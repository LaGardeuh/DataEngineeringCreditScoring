# Credit Scoring - Home Credit Default Risk

Syst√®me de scoring cr√©dit bas√© sur l'apprentissage automatique pour pr√©dire le risque de d√©faut de paiement.

---

## Contexte

En tant que Data Scientist au sein d'une soci√©t√© financi√®re, ce projet vise √† d√©velopper un outil de **credit scoring** permettant :

### Enjeu Principal

**Un faux n√©gatif (FN) co√ªte 10√ó plus qu'un faux positif (FP)**

- **Faux N√©gatif (FN)** : Accorder un cr√©dit √† un client qui fera d√©faut ‚Üí Perte de ~10√ó le montant du pr√™t
- **Faux Positif (FP)** : Refuser un cr√©dit √† un bon client ‚Üí Perte de 1√ó profit potentiel

---

## Mod√®le Champion : LightGBM

Apr√®s comparaison de 4 mod√®les (Logistic Regression, Random Forest, XGBoost, LightGBM), le mod√®le **LightGBM** a √©t√© s√©lectionn√©.

### Performances

| M√©trique | Valeur |
|----------|--------|
| **Mod√®le** | LightGBM |
| **AUC** | 0.7793 |
| **Accuracy** | 0.7246 |
| **Precision** | 0.1826 |
| **Recall** | 0.6935 |
| **F1-Score** | 0.2891 |
| **Co√ªt M√©tier** | **30,600** |
| **Seuil Optimal** | **0.5152** |

### R√®gle de D√©cision

```python
if probabilit√©_d√©faut >= 0.5152:
    d√©cision = "REFUSER le cr√©dit"  # Risque √©lev√©
else:
    d√©cision = "ACCEPTER le cr√©dit"  # Risque acceptable
```

### Justification du Seuil

Le seuil de **0.5152** a √©t√© optimis√© pour minimiser le co√ªt m√©tier total :
```
Co√ªt Total = (Faux N√©gatifs √ó 10) + (Faux Positifs √ó 1)
```

Ce seuil repr√©sente le meilleur √©quilibre entre :
- Minimiser les d√©fauts non d√©tect√©s (FN) qui co√ªtent cher
- Accepter un nombre raisonnable de faux positifs (FP)

---

## üìä Comparaison des Mod√®les

| Mod√®le | AUC | Co√ªt M√©tier | Seuil Optimal |
|--------|-----|-------------|---------------|
| **LightGBM** üèÜ | **0.7793** | **30,600** | 0.5152 |
| XGBoost | 0.7695 | 31,411 | 0.5253 |
| Logistic Regression | 0.7684 | 31,714 | 0.5152 |
| Random Forest | 0.7553 | 32,783 | 0.1616 |

**LightGBM** offre le meilleur compromis avec :
---

## üõ†Ô∏è Installation

### Pr√©requis

- Python 3.11+
- Docker
- Git

### √âtape 1 : Cloner le D√©p√¥t

```bash
git clone <url-du-repo>
cd "Projet Final"
```

### √âtape 2 : Cr√©er un Environnement Virtuel

```bash
python3 -m venv .venv
source .venv/bin/activate 
```

### √âtape 3 : Installer les D√©pendances

```bash
pip install -r requirements.txt
```

---

##  Utilisation

### 1. Exploration des Donn√©es

```bash
jupyter notebook notebooks/01_data_preparation.ipynb
```

### 2. Entra√Ænement des Mod√®les

```bash
# D√©marrer MLflow UI (dans un terminal s√©par√©)
mlflow ui

# Ouvrir le notebook d'entra√Ænement
jupyter notebook notebooks/02_model_training.ipynb
```

Visualiser les exp√©riences : http://localhost:5000

### 3. Analyse d'Explicabilit√© (SHAP)

```bash
jupyter notebook notebooks/03_explainability.ipynb
```

### 4. Test du Serving MLflow

```bash
jupyter notebook notebooks/04_mlflow_serving_test.ipynb
```

---

## üê≥ D√©ploiement avec Docker

### Construction de l'Image

```bash
docker build -t credit-scoring:latest .
```

### Lancement du Conteneur

```bash
docker run -p 1234:1234 credit-scoring:latest
```

Le serveur d'inf√©rence sera accessible sur `http://localhost:1234`

### Alternative : Docker Compose

```bash
docker-compose up
```

---

## üîå Test de l'API

### Commande curl

```bash
curl -X POST http://localhost:1234/invocations \
  -H 'Content-Type: application/json' \
  -d @sample_request.json
```

### Format de la Requ√™te

```json
{
  "dataframe_split": {
    "columns": ["feature1", "feature2", "..."],
    "data": [[valeur1, valeur2, ...]]
  }
}
```

### R√©ponse Attendue

```json
[0.3456]  # Probabilit√© de d√©faut (entre 0 et 1)
```

**Interpr√©tation** :
- Si probabilit√© < 0.5152 ‚Üí **Accepter** le cr√©dit
- Si probabilit√© ‚â• 0.5152 ‚Üí **Refuser** le cr√©dit
---

## üìÅ Structure du Projet

```
Projet Final/
‚îÇ
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile                     # Configuration Docker
‚îú‚îÄ‚îÄ docker-compose.yml             # Orchestration Docker
‚îú‚îÄ‚îÄ .gitignore                     # Fichiers √† exclure de Git
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Notebooks Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_preparation.ipynb     # Pr√©paration des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ 02_model_training.ipynb       # Entra√Ænement des mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ 03_explainability.ipynb       # Analyse SHAP
‚îÇ   ‚îî‚îÄ‚îÄ 04_mlflow_serving_test.ipynb  # Test du serving
‚îÇ
‚îú‚îÄ‚îÄ src/                           # Code source Python
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py                  # Fonctions de pr√©paration
‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py                # Utilitaires de mod√©lisation
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                    # M√©triques m√©tier
‚îÇ   ‚îî‚îÄ‚îÄ explainability.py             # Fonctions SHAP
‚îÇ
‚îú‚îÄ‚îÄ model/                         # Mod√®le MLflow (LightGBM)
‚îÇ   ‚îú‚îÄ‚îÄ MLmodel                       # M√©tadonn√©es MLflow
‚îÇ   ‚îú‚îÄ‚îÄ conda.yaml                    # Environnement conda
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl                     # Mod√®le s√©rialis√© (371 KB)
‚îÇ   ‚îú‚îÄ‚îÄ python_env.yaml               # Environnement Python
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt              # D√©pendances du mod√®le
‚îÇ
‚îú‚îÄ‚îÄ models/                        # Mod√®les entra√Æn√©s (sauvegarde)
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm.pkl
‚îÇ   ‚îú‚îÄ‚îÄ xgboost.pkl
‚îÇ   ‚îú‚îÄ‚îÄ random_forest.pkl
‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression.pkl
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl
‚îÇ
‚îú‚îÄ‚îÄ reports/                       # Rapports et visualisations
‚îÇ   ‚îú‚îÄ‚îÄ rapport_credit_scoring.pdf    # Rapport final (2-3 pages)
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv          # Comparaison des mod√®les
‚îÇ   ‚îî‚îÄ‚îÄ figures/                      # Graphiques
‚îÇ       ‚îú‚îÄ‚îÄ shap_global.png              # Importance globale
‚îÇ       ‚îú‚îÄ‚îÄ shap_local.png               # Importance locale
‚îÇ       ‚îú‚îÄ‚îÄ shap_summary.png
‚îÇ       ‚îî‚îÄ‚îÄ model_comparison.png
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Donn√©es (non versionn√©es)
‚îÇ   ‚îî‚îÄ‚îÄ application_train_prepared.csv
‚îÇ
‚îî‚îÄ‚îÄ mlruns/                        # Tracking MLflow (non versionn√©)
```

---

## üî¨ MLflow - Suivi des Exp√©rimentations

### D√©marrer le Serveur MLflow

```bash
mlflow ui
```

Acc√©der √† l'interface : http://localhost:5000


### Mod√®les Enregistr√©s

- **Nom** : `credit_scoring_model`
- **Version active** : LightGBM (la plus r√©cente)
- **Run ID** : Consultable dans MLflow UI

---

## üìà M√©triques et Optimisation

### Fonction de Co√ªt M√©tier

```python
Co√ªt Total = (FN √ó 10) + (FP √ó 1)
```

O√π :
- **FN** = Nombre de faux n√©gatifs (d√©fauts non d√©tect√©s)
- **FP** = Nombre de faux positifs (bons clients refus√©s)

### Strat√©gie d'Optimisation

1. **Validation crois√©e** : StratifiedKFold (5 folds)
2. **Gestion du d√©s√©quilibre** : `class_weight='balanced'`
3. **Hyperparam√®tres** : RandomizedSearchCV
4. **Seuil m√©tier** : Optimisation sur fonction de co√ªt

### D√©s√©quilibre des Classes

- **Bons clients (0)** : 91.9%
- **Mauvais clients (1)** : 8.1%
- **Ratio** : 11.39:1


Cr√©dits: IR4 2027 - Thomas B√©chu, No√© Guengant, Malo Kerautret
